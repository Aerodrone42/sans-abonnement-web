import { useState, useRef, useEffect } from 'react';
import { EnhancedChatGPTService } from '@/services/enhancedChatGptService';
import { SpeechSynthesisService } from '@/services/speechSynthesisService';

interface UseVoiceRecognitionProps {
  onTranscript: (text: string, field: string) => void;
  conversationMode: boolean;
  chatGPT: EnhancedChatGPTService | null;
}

interface ExtendedSpeechRecognition extends SpeechRecognition {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

export const useVoiceRecognition = ({ onTranscript, conversationMode, chatGPT }: UseVoiceRecognitionProps) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [lastResponse, setLastResponse] = useState("");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConversationActive, setIsConversationActive] = useState(false);
  
  const recognitionRef = useRef<ExtendedSpeechRecognition | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const speechSynthesis = useRef(new SpeechSynthesisService()).current;
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  
  // √âtats de contr√¥le simplifi√©s
  const shouldContinueRef = useRef(false);
  const isActiveSessionRef = useRef(false);
  const lastTranscriptRef = useRef("");
  const interimResultRef = useRef("");

  const cleanup = () => {
    console.log('üßπ Nettoyage COMPLET microphone');
    
    // Arr√™ter TOUT
    shouldContinueRef.current = false;
    isActiveSessionRef.current = false;
    
    setIsListening(false);
    setIsConversationActive(false);
    setIsProcessing(false);
    setIsSpeaking(false);
    
    // Nettoyer les timeouts
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }
    
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    
    // Arr√™ter le stream audio
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('üé§ Track audio ferm√©');
      });
      mediaStreamRef.current = null;
    }

    // Arr√™ter la reconnaissance vocale
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
        console.log('üîá Recognition ARR√äT√âE');
      } catch (error) {
        console.log('Recognition d√©j√† arr√™t√©e');
      }
    }

    // Arr√™ter la synth√®se vocale
    speechSynthesis.stop();
    console.log('‚úÖ Nettoyage TERMIN√â');
  };

  const stopSpeaking = () => {
    console.log('üõë ARR√äT TOTAL demand√© par utilisateur');
    cleanup();
  };

  const startRecognitionSafely = () => {
    // V√©rifications de s√©curit√© STRICTES
    if (!recognitionRef.current) {
      console.log('‚ùå Recognition non disponible');
      return false;
    }

    if (!shouldContinueRef.current || !isActiveSessionRef.current) {
      console.log('‚ùå Session non active, arr√™t du d√©marrage');
      return false;
    }

    if (!chatGPT) {
      console.log('‚ùå ChatGPT non disponible');
      return false;
    }

    if (isListening) {
      console.log('‚ö†Ô∏è D√©j√† en √©coute, ignorer');
      return false;
    }

    try {
      recognitionRef.current.start();
      console.log('‚úÖ Recognition d√©marr√©e');
      return true;
    } catch (error) {
      console.error('‚ùå Erreur d√©marrage recognition:', error);
      setIsListening(false);
      return false;
    }
  };

  const processAIResponse = async (finalTranscript: string) => {
    console.log('ü§ñ D√âBUT TRAITEMENT IA:', finalTranscript);
    
    if (!shouldContinueRef.current || !isActiveSessionRef.current) {
      console.log('‚ùå Session arr√™t√©e, abandon traitement IA');
      return;
    }
    
    if (!finalTranscript || finalTranscript.trim().length < 2) {
      console.log('‚ùå Transcript trop court');
      return;
    }

    setIsProcessing(true);
    
    // Arr√™ter temporairement le micro pendant traitement IA
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.log('Erreur arr√™t micro pour IA');
      }
    }

    if (!chatGPT) {
      console.log('‚ùå ChatGPT indisponible, mode dict√©e');
      setTimeout(() => {
        setIsProcessing(false);
        onTranscript(finalTranscript, "message");
        
        // Red√©marrer le micro si session active
        if (shouldContinueRef.current && isActiveSessionRef.current) {
          setTimeout(() => startRecognitionSafely(), 1000);
        }
      }, 500);
      return;
    }
    
    if (!conversationMode) {
      console.log('Mode dict√©e');
      setTimeout(() => {
        setIsProcessing(false);
        onTranscript(finalTranscript, "message");
        
        // Red√©marrer le micro si session active
        if (shouldContinueRef.current && isActiveSessionRef.current) {
          setTimeout(() => startRecognitionSafely(), 1000);
        }
      }, 1500);
      return;
    }

    try {
      console.log('üöÄ ENVOI √Ä ChatGPT:', finalTranscript);
      const response = await chatGPT.sendMessage(finalTranscript);
      console.log('‚úÖ R√©ponse ChatGPT:', response);
      setLastResponse(response);
      
      setIsSpeaking(true);
      
      speechSynthesis.speak(response, () => {
        console.log('‚úÖ Synth√®se termin√©e');
        setIsSpeaking(false);
        setIsProcessing(false);
        
        // Red√©marrer le micro SEULEMENT si session toujours active
        if (shouldContinueRef.current && isActiveSessionRef.current && chatGPT) {
          setTimeout(() => {
            startRecognitionSafely();
          }, 1000);
        }
      });
      
    } catch (error) {
      console.error('‚ùå Erreur ChatGPT:', error);
      setIsProcessing(false);
      
      // Red√©marrer le micro m√™me en cas d'erreur si session active
      if (shouldContinueRef.current && isActiveSessionRef.current) {
        setTimeout(() => startRecognitionSafely(), 2000);
      }
    }
  };

  const startListening = async () => {
    console.log('üéØ D√âMARRAGE conversation');
    
    if (!recognitionRef.current || !chatGPT) {
      console.log('‚ùå Conditions non remplies pour d√©marrer');
      return;
    }

    // Arr√™ter toute synth√®se en cours
    if (isSpeaking) {
      speechSynthesis.stop();
      setIsSpeaking(false);
    }

    try {
      // Demander permission micro
      if (!mediaStreamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        mediaStreamRef.current = stream;
        console.log('‚úÖ Permission micro obtenue');
      }

      // ACTIVER la session
      shouldContinueRef.current = true;
      isActiveSessionRef.current = true;
      setIsConversationActive(true);

      console.log('üöÄ D√©marrage reconnaissance vocale');
      startRecognitionSafely();
      
    } catch (error) {
      console.error('‚ùå Erreur d√©marrage:', error);
      cleanup();
    }
  };

  const stopListening = () => {
    console.log('üõë ARR√äT conversation demand√©');
    
    // D√âSACTIVER la session
    shouldContinueRef.current = false;
    isActiveSessionRef.current = false;
    setIsConversationActive(false);
    
    cleanup();
  };

  useEffect(() => {
    console.log('üîÑ Initialisation reconnaissance vocale');
    
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognitionClass = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognitionClass() as ExtendedSpeechRecognition;
      recognitionRef.current = recognition;
      
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'fr-FR';
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        console.log('üé§ Recognition D√âMARR√âE');
        setIsListening(true);
      };

      recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }
        
        if (interimTranscript) {
          interimResultRef.current = interimTranscript;
          const displayText = lastTranscriptRef.current + interimTranscript;
          setTranscript(displayText);
        }
        
        if (finalTranscript.trim()) {
          console.log('üéØ TRANSCRIPT FINAL:', finalTranscript);
          lastTranscriptRef.current += finalTranscript;
          setTranscript(lastTranscriptRef.current);
          
          // Annuler timeout pr√©c√©dent
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current);
            silenceTimeoutRef.current = null;
          }
          
          // CORRECTION: D√©clencher imm√©diatement le traitement IA
          if (shouldContinueRef.current && 
              isActiveSessionRef.current && 
              lastTranscriptRef.current.trim() &&
              chatGPT &&
              conversationMode) {
            
            console.log('üöÄ TRAITEMENT IA IMM√âDIAT');
            processAIResponse(lastTranscriptRef.current.trim());
            lastTranscriptRef.current = "";
            interimResultRef.current = "";
            setTranscript("");
          } else if (!conversationMode) {
            // En mode dict√©e, juste remplir le formulaire
            setTimeout(() => {
              onTranscript(lastTranscriptRef.current.trim(), "message");
              lastTranscriptRef.current = "";
              setTranscript("");
            }, 1000);
          }
        }
      };

      recognition.onerror = (event) => {
        console.error('‚ùå Erreur recognition:', event.error);
        setIsListening(false);
        
        if (event.error === 'not-allowed') {
          console.error('‚ùå Permission microphone refus√©e');
          stopListening();
          return;
        }
        
        // Red√©marrer UNIQUEMENT si session active et conditions remplies
        if (shouldContinueRef.current && 
            isActiveSessionRef.current && 
            chatGPT &&
            !isProcessing &&
            !isSpeaking) {
          
          console.log('üîÑ Red√©marrage apr√®s erreur');
          restartTimeoutRef.current = setTimeout(() => {
            if (shouldContinueRef.current && isActiveSessionRef.current) {
              startRecognitionSafely();
            }
          }, 1000);
        }
      };

      recognition.onend = () => {
        console.log('üèÅ Recognition termin√©e');
        setIsListening(false);
        
        // Red√©marrer UNIQUEMENT si session active
        if (shouldContinueRef.current && 
            isActiveSessionRef.current && 
            chatGPT &&
            !isProcessing &&
            !isSpeaking) {
          
          console.log('üîÑ Auto-restart recognition');
          restartTimeoutRef.current = setTimeout(() => {
            if (shouldContinueRef.current && isActiveSessionRef.current) {
              startRecognitionSafely();
            }
          }, 500);
        } else {
          console.log('üö´ Auto-restart ignor√© - session inactive');
        }
      };
      
      console.log('üéôÔ∏è Speech Recognition PR√äTE');
    }

    return cleanup;
  }, []);

  return {
    isListening,
    transcript,
    isProcessing,
    lastResponse,
    isSpeaking,
    isConversationActive,
    startListening,
    stopListening,
    stopSpeaking,
    cleanupMicrophone: cleanup
  };
};
