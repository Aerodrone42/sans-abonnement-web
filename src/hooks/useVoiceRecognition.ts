
import { useState, useRef, useEffect } from 'react';
import { EnhancedChatGPTService } from '@/services/enhancedChatGptService';
import { SpeechSynthesisService } from '@/services/speechSynthesisService';

interface UseVoiceRecognitionProps {
  onTranscript: (text: string, field: string) => void;
  conversationMode: boolean;
  chatGPT: EnhancedChatGPTService | null;
}

interface ExtendedSpeechRecognition extends SpeechRecognition {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

export const useVoiceRecognition = ({ onTranscript, conversationMode, chatGPT }: UseVoiceRecognitionProps) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [lastResponse, setLastResponse] = useState("");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConversationActive, setIsConversationActive] = useState(false);
  
  const recognitionRef = useRef<ExtendedSpeechRecognition | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const speechSynthesis = useRef(new SpeechSynthesisService()).current;
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  
  const shouldContinueRef = useRef(false);
  const processingRef = useRef(false);
  const speakingRef = useRef(false);
  const lastTranscriptRef = useRef("");
  const interimResultRef = useRef("");
  const isStoppedRef = useRef(true);
  const microphoneMutedRef = useRef(false);
  const recognitionActiveRef = useRef(false);
  const conversationActiveRef = useRef(false);

  const cleanup = () => {
    console.log('ğŸ§¹ Nettoyage complet microphone');
    shouldContinueRef.current = false;
    speakingRef.current = false;
    isStoppedRef.current = true;
    microphoneMutedRef.current = false;
    recognitionActiveRef.current = false;
    conversationActiveRef.current = false;
    setIsListening(false);
    setIsConversationActive(false);
    
    // CORRECTION: Nettoyer tous les timeouts pour Ã©viter les redÃ©marrages
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }
    
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.log('Recognition dÃ©jÃ  arrÃªtÃ©e');
      }
    }
  };

  const stopSpeaking = () => {
    console.log('ğŸ›‘ ARRÃŠT COMPLET DEMANDÃ‰');
    cleanup();
    speechSynthesis.stop();
    setIsSpeaking(false);
    setIsProcessing(false);
    processingRef.current = false;
  };

  const muteMicrophoneForSpeech = () => {
    console.log('ğŸ¤âŒ MICRO FORCÃ‰ ARRÃŠT - IA va parler');
    microphoneMutedRef.current = true;
    recognitionActiveRef.current = false;
    setIsListening(false);
    
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
        console.log('ğŸ”‡ Reconnaissance vocale FORCÃ‰E ARRÃŠT pendant synthÃ¨se');
      } catch (error) {
        console.log('Erreur arrÃªt recognition pour synthÃ¨se');
      }
    }
  };

  const unmuteMicrophoneAfterSpeech = () => {
    console.log('ğŸ¤âœ… MICRO RÃ‰ACTIVÃ‰ - IA a fini de parler');
    microphoneMutedRef.current = false;
    
    setTimeout(() => {
      // CORRECTION: VÃ©rifications plus strictes pour Ã©viter les redÃ©marrages intempestifs
      if (conversationActiveRef.current && 
          !isStoppedRef.current && 
          !speakingRef.current && 
          !processingRef.current && 
          !recognitionActiveRef.current &&
          !microphoneMutedRef.current) {
        console.log('ğŸ”„ RedÃ©marrage micro aprÃ¨s synthÃ¨se');
        startRecognitionSafely();
      } else {
        console.log('ğŸš« RedÃ©marrage micro annulÃ© - conditions non remplies');
      }
    }, 1000);
  };

  const startRecognitionSafely = () => {
    if (!recognitionRef.current) {
      console.log('âŒ Recognition non disponible');
      return false;
    }

    if (recognitionActiveRef.current) {
      console.log('âš ï¸ Recognition dÃ©jÃ  active, ignorer le dÃ©marrage');
      return false;
    }

    // CORRECTION: VÃ©rifier que la conversation est active
    if (!conversationActiveRef.current) {
      console.log('âŒ Conversation non active, arrÃªt du dÃ©marrage');
      return false;
    }

    try {
      shouldContinueRef.current = true;
      recognitionActiveRef.current = true;
      recognitionRef.current.start();
      console.log('âœ… Recognition dÃ©marrÃ©e avec succÃ¨s');
      return true;
    } catch (error) {
      console.error('âŒ Erreur dÃ©marrage recognition:', error);
      recognitionActiveRef.current = false;
      setIsListening(false);
      return false;
    }
  };

  const processAIResponse = async (finalTranscript: string) => {
    console.log('ğŸ¤– DÃ‰BUT TRAITEMENT IA:', finalTranscript);
    
    // CORRECTION: VÃ©rifications plus strictes
    if (isStoppedRef.current || !conversationActiveRef.current) {
      console.log('âŒ Traitement annulÃ© - conversation arrÃªtÃ©e');
      return;
    }
    
    if (!finalTranscript || finalTranscript.trim().length < 2) {
      console.log('âŒ Transcript trop court, ignorÃ©:', finalTranscript);
      return;
    }

    console.log('ğŸ”¥ ACTIVATION PROCESSING');
    setIsProcessing(true);
    processingRef.current = true;
    
    muteMicrophoneForSpeech();

    if (!chatGPT) {
      console.log('âŒ ChatGPT non initialisÃ©, mode dictÃ©e seulement');
      setTimeout(() => {
        setIsProcessing(false);
        processingRef.current = false;
        unmuteMicrophoneAfterSpeech();
        onTranscript(finalTranscript, "message");
      }, 500);
      return;
    }
    
    if (!conversationMode) {
      console.log('Mode dictÃ©e activÃ©');
      setTimeout(() => {
        setIsProcessing(false);
        processingRef.current = false;
        unmuteMicrophoneAfterSpeech();
        onTranscript(finalTranscript, "message");
      }, 1500);
      return;
    }

    try {
      console.log('ğŸ“¤ Envoi Ã  ChatGPT...');
      const response = await chatGPT.sendMessage(finalTranscript);
      
      console.log('âœ… RÃ©ponse ChatGPT reÃ§ue:', response);
      
      setIsSpeaking(true);
      speakingRef.current = true;
      
      console.log('ğŸ”Š DÃ©but synthÃ¨se vocale');
      speechSynthesis.speak(response, () => {
        console.log('âœ… SynthÃ¨se terminÃ©e');
        setIsSpeaking(false);
        speakingRef.current = false;
        setIsProcessing(false);
        processingRef.current = false;
        unmuteMicrophoneAfterSpeech();
      });
      
    } catch (error) {
      console.error('âŒ Erreur ChatGPT:', error);
      setIsProcessing(false);
      processingRef.current = false;
      setTimeout(() => {
        unmuteMicrophoneAfterSpeech();
      }, 2000);
    }
  };

  const startListening = async () => {
    console.log('ğŸ¯ DÃ‰MARRAGE conversation');
    
    if (!recognitionRef.current) {
      console.log('âŒ Recognition indisponible');
      return;
    }

    if (isSpeaking) {
      speechSynthesis.stop();
      setIsSpeaking(false);
      speakingRef.current = false;
    }

    try {
      console.log('ğŸ¤ Demande permission micro...');
      if (!mediaStreamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        mediaStreamRef.current = stream;
        console.log('âœ… Permission micro obtenue');
      }

      isStoppedRef.current = false;
      microphoneMutedRef.current = false;
      conversationActiveRef.current = true;
      setIsConversationActive(true);

      console.log('ğŸš€ DÃ©marrage reconnaissance vocale');
      const started = startRecognitionSafely();
      
      if (started) {
        console.log('âœ… Conversation ACTIVE');
      } else {
        console.log('âŒ Ã‰chec dÃ©marrage conversation');
      }
    } catch (error) {
      console.error('âŒ Erreur dÃ©marrage:', error);
      cleanup();
    }
  };

  const stopListening = () => {
    console.log('ğŸ›‘ ARRÃŠT conversation demandÃ©');
    conversationActiveRef.current = false;
    setIsConversationActive(false);
    stopSpeaking();
  };

  useEffect(() => {
    console.log('ğŸ”„ Initialisation reconnaissance vocale');
    
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognitionClass = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognitionClass() as ExtendedSpeechRecognition;
      recognitionRef.current = recognition;
      
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'fr-FR';
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        console.log('ğŸ¤ Recognition dÃ©marrÃ©e - Ã‰COUTE ACTIVE');
        recognitionActiveRef.current = true;
        setIsListening(true);
      };

      recognition.onresult = (event) => {
        console.log('ğŸ¯ RÃ‰SULTAT VOCAL REÃ‡U');
        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }
        
        if (interimTranscript) {
          interimResultRef.current = interimTranscript;
          const displayText = lastTranscriptRef.current + interimTranscript;
          setTranscript(displayText);
          console.log('ğŸ“ AFFICHAGE INTERIM:', displayText);
        }
        
        if (finalTranscript.trim()) {
          console.log('ğŸ¯ TRANSCRIPT FINAL:', finalTranscript);
          lastTranscriptRef.current += finalTranscript;
          setTranscript(lastTranscriptRef.current);
          
          if (silenceTimeoutRef.current) {
            console.log('â° Annulation timeout prÃ©cÃ©dent');
            clearTimeout(silenceTimeoutRef.current);
            silenceTimeoutRef.current = null;
          }
          
          console.log('â° NOUVEAU TIMEOUT de 3s pour traitement IA');
          silenceTimeoutRef.current = setTimeout(() => {
            console.log('â° TIMEOUT DÃ‰CLENCHÃ‰ - VÃ©rification conditions');
            
            // CORRECTION: Conditions plus strictes et claires
            const canProcess = conversationActiveRef.current && 
                              !isStoppedRef.current && 
                              !microphoneMutedRef.current && 
                              !processingRef.current &&
                              lastTranscriptRef.current.trim();
            
            console.log('ğŸ” CONDITIONS:', {
              conversationActive: conversationActiveRef.current,
              notStopped: !isStoppedRef.current,
              micNotMuted: !microphoneMutedRef.current,
              notProcessing: !processingRef.current,
              hasTranscript: !!lastTranscriptRef.current.trim()
            });
            
            if (canProcess) {
              console.log('ğŸš€ LANCEMENT TRAITEMENT IA');
              processAIResponse(lastTranscriptRef.current.trim());
              lastTranscriptRef.current = "";
              interimResultRef.current = "";
              setTranscript("");
            } else {
              console.log('âŒ CONDITIONS NON REMPLIES pour traitement IA');
            }
          }, 3000);
        }
      };

      recognition.onerror = (event) => {
        console.error('âŒ Erreur recognition:', event.error);
        recognitionActiveRef.current = false;
        setIsListening(false);
        
        if (event.error === 'not-allowed') {
          console.error('âŒ Permission microphone refusÃ©e');
          conversationActiveRef.current = false;
          setIsConversationActive(false);
          return;
        }
        
        // CORRECTION: Ne redÃ©marrer que si vraiment nÃ©cessaire
        if (conversationActiveRef.current && 
            !processingRef.current && 
            !speakingRef.current && 
            !isStoppedRef.current && 
            !microphoneMutedRef.current) {
          console.log('ğŸ”„ RedÃ©marrage aprÃ¨s erreur dans 1s');
          restartTimeoutRef.current = setTimeout(() => {
            if (conversationActiveRef.current && 
                !speakingRef.current && 
                !processingRef.current && 
                !isStoppedRef.current && 
                !microphoneMutedRef.current) {
              startRecognitionSafely();
            }
          }, 1000);
        }
      };

      recognition.onend = () => {
        console.log('ğŸ Recognition terminÃ©e');
        recognitionActiveRef.current = false;
        setIsListening(false);
        
        // CORRECTION: Ne redÃ©marrer que si toutes les conditions sont remplies
        if (conversationActiveRef.current && 
            !processingRef.current && 
            !speakingRef.current && 
            !isStoppedRef.current && 
            !microphoneMutedRef.current) {
          console.log('ğŸ”„ Auto-restart recognition dans 500ms');
          restartTimeoutRef.current = setTimeout(() => {
            if (conversationActiveRef.current && 
                !speakingRef.current && 
                !processingRef.current && 
                !isStoppedRef.current && 
                !microphoneMutedRef.current && 
                !recognitionActiveRef.current) {
              startRecognitionSafely();
            }
          }, 500);
        } else {
          console.log('ğŸš« Auto-restart ignorÃ© - conditions non remplies');
        }
      };
      
      console.log('ğŸ™ï¸ Speech Recognition configurÃ©e et PRÃŠTE');
    }

    return cleanup;
  }, []);

  return {
    isListening,
    transcript,
    isProcessing,
    lastResponse,
    isSpeaking,
    isConversationActive,
    startListening,
    stopListening,
    stopSpeaking,
    cleanupMicrophone: cleanup
  };
};
