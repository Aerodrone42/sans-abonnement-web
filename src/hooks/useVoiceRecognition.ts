
import { useState, useRef, useEffect } from 'react';
import { EnhancedChatGPTService } from '@/services/enhancedChatGptService';
import { SpeechSynthesisService } from '@/services/speechSynthesisService';

interface UseVoiceRecognitionProps {
  onTranscript: (text: string, field: string) => void;
  conversationMode: boolean;
  chatGPT: EnhancedChatGPTService | null;
}

interface ExtendedSpeechRecognition extends SpeechRecognition {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

export const useVoiceRecognition = ({ onTranscript, conversationMode, chatGPT }: UseVoiceRecognitionProps) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [lastResponse, setLastResponse] = useState("");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConversationActive, setIsConversationActive] = useState(false);
  
  const recognitionRef = useRef<ExtendedSpeechRecognition | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const speechSynthesis = useRef(new SpeechSynthesisService()).current;
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  
  // CORRECTION: Variables de contrÃ´le simplifiÃ©es
  const shouldStayActiveRef = useRef(false);
  const currentTranscriptRef = useRef("");

  const stopEverything = () => {
    console.log('ğŸ›‘ ARRÃŠT TOTAL du microphone');
    
    // DÃ©sactiver TOUT
    shouldStayActiveRef.current = false;
    setIsListening(false);
    setIsConversationActive(false);
    setIsProcessing(false);
    setIsSpeaking(false);
    
    // Nettoyer les timeouts
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }
    
    // ArrÃªter le stream audio
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('ğŸ¤ Track audio fermÃ©');
      });
      mediaStreamRef.current = null;
    }

    // ArrÃªter la reconnaissance vocale
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
        console.log('ğŸ”‡ Recognition STOP forcÃ©');
      } catch (error) {
        console.log('Recognition dÃ©jÃ  arrÃªtÃ©e');
      }
    }

    // ArrÃªter la synthÃ¨se vocale
    speechSynthesis.stop();
    console.log('âœ… ARRÃŠT TOTAL terminÃ©');
  };

  const processAIResponse = async (finalTranscript: string) => {
    console.log('ğŸ¤– Traitement IA:', finalTranscript);
    
    if (!shouldStayActiveRef.current) {
      console.log('âŒ Session arrÃªtÃ©e, abandon traitement');
      return;
    }
    
    if (!finalTranscript || finalTranscript.trim().length < 2) {
      console.log('âŒ Transcript trop court');
      return;
    }

    setIsProcessing(true);

    if (!chatGPT) {
      console.log('âŒ ChatGPT indisponible');
      setTimeout(() => {
        setIsProcessing(false);
        onTranscript(finalTranscript, "message");
      }, 500);
      return;
    }
    
    if (!conversationMode) {
      console.log('Mode dictÃ©e');
      setTimeout(() => {
        setIsProcessing(false);
        onTranscript(finalTranscript, "message");
      }, 1500);
      return;
    }

    try {
      console.log('ğŸš€ Envoi Ã  ChatGPT:', finalTranscript);
      const response = await chatGPT.sendMessage(finalTranscript);
      console.log('âœ… RÃ©ponse ChatGPT:', response);
      setLastResponse(response);
      
      setIsSpeaking(true);
      
      speechSynthesis.speak(response, () => {
        console.log('âœ… SynthÃ¨se terminÃ©e');
        setIsSpeaking(false);
        setIsProcessing(false);
        
        // RedÃ©marrer seulement si encore actif
        if (shouldStayActiveRef.current && chatGPT) {
          setTimeout(() => {
            if (shouldStayActiveRef.current && recognitionRef.current) {
              try {
                recognitionRef.current.start();
                console.log('ğŸ”„ RedÃ©marrage aprÃ¨s IA');
              } catch (error) {
                console.log('Erreur redÃ©marrage aprÃ¨s IA');
              }
            }
          }, 1000);
        }
      });
      
    } catch (error) {
      console.error('âŒ Erreur ChatGPT:', error);
      setIsProcessing(false);
    }
  };

  const startListening = async () => {
    console.log('ğŸ¯ DÃ‰MARRAGE conversation');
    
    if (!recognitionRef.current || !chatGPT) {
      console.log('âŒ Conditions non remplies');
      return;
    }

    // ArrÃªter toute synthÃ¨se en cours
    if (isSpeaking) {
      speechSynthesis.stop();
      setIsSpeaking(false);
    }

    try {
      // Demander permission micro
      if (!mediaStreamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        });
        mediaStreamRef.current = stream;
        console.log('âœ… Permission micro obtenue');
      }

      // ACTIVER la session
      shouldStayActiveRef.current = true;
      setIsConversationActive(true);
      currentTranscriptRef.current = "";
      setTranscript("");

      console.log('ğŸš€ DÃ©marrage reconnaissance');
      recognitionRef.current.start();
      
    } catch (error) {
      console.error('âŒ Erreur dÃ©marrage:', error);
      stopEverything();
    }
  };

  const stopListening = () => {
    console.log('ğŸ›‘ ARRÃŠT demandÃ© par utilisateur');
    stopEverything();
  };

  const stopSpeaking = () => {
    console.log('ğŸ›‘ ARRÃŠT COMPLET demandÃ©');
    stopEverything();
  };

  useEffect(() => {
    console.log('ğŸ”„ Initialisation reconnaissance vocale');
    
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognitionClass = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognitionClass() as ExtendedSpeechRecognition;
      recognitionRef.current = recognition;
      
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'fr-FR';
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        console.log('ğŸ¤ Recognition DÃ‰MARRÃ‰E');
        setIsListening(true);
      };

      recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }
        
        if (interimTranscript) {
          const displayText = currentTranscriptRef.current + interimTranscript;
          setTranscript(displayText);
        }
        
        // CORRECTION: Quand on a un transcript final, on ARRÃŠTE la reconnaissance et on traite
        if (finalTranscript.trim()) {
          console.log('ğŸ¯ TRANSCRIPT FINAL:', finalTranscript);
          currentTranscriptRef.current += finalTranscript;
          setTranscript(currentTranscriptRef.current);
          
          // ARRÃŠTER la reconnaissance pour traiter l'IA
          if (recognitionRef.current) {
            try {
              recognitionRef.current.stop();
              console.log('ğŸ”‡ ArrÃªt pour traitement IA');
            } catch (error) {
              console.log('Erreur arrÃªt pour IA');
            }
          }
          
          // Traiter avec l'IA si en mode conversation
          if (shouldStayActiveRef.current && 
              currentTranscriptRef.current.trim() &&
              chatGPT &&
              conversationMode) {
            
            console.log('ğŸš€ Traitement IA');
            processAIResponse(currentTranscriptRef.current.trim());
            currentTranscriptRef.current = "";
            setTranscript("");
          } else if (!conversationMode) {
            // Mode dictÃ©e
            setTimeout(() => {
              onTranscript(currentTranscriptRef.current.trim(), "message");
              currentTranscriptRef.current = "";
              setTranscript("");
            }, 1000);
          }
        }
      };

      recognition.onerror = (event) => {
        console.error('âŒ Erreur recognition:', event.error);
        setIsListening(false);
        
        if (event.error === 'not-allowed') {
          console.error('âŒ Permission refusÃ©e');
          stopEverything();
          return;
        }
        
        // Ne redÃ©marre QUE si vraiment nÃ©cessaire
        if (shouldStayActiveRef.current && 
            chatGPT &&
            !isProcessing &&
            !isSpeaking &&
            event.error !== 'aborted') {
          
          console.log('ğŸ”„ RedÃ©marrage aprÃ¨s erreur');
          restartTimeoutRef.current = setTimeout(() => {
            if (shouldStayActiveRef.current && recognitionRef.current) {
              try {
                recognitionRef.current.start();
              } catch (error) {
                console.log('Erreur redÃ©marrage');
              }
            }
          }, 1000);
        }
      };

      recognition.onend = () => {
        console.log('ğŸ Recognition terminÃ©e');
        setIsListening(false);
        
        // CORRECTION: Ne redÃ©marre PAS automatiquement ici
        // Le redÃ©marrage se fait uniquement aprÃ¨s traitement IA ou en cas d'erreur
        console.log('ğŸš« Pas de redÃ©marrage automatique');
      };
      
      console.log('ğŸ™ï¸ Speech Recognition PRÃŠTE');
    }

    return stopEverything;
  }, []);

  return {
    isListening,
    transcript,
    isProcessing,
    lastResponse,
    isSpeaking,
    isConversationActive,
    startListening,
    stopListening,
    stopSpeaking,
    cleanupMicrophone: stopEverything
  };
};
