
import { useState, useRef, useEffect } from 'react';
import { EnhancedChatGPTService } from '@/services/enhancedChatGptService';
import { SpeechSynthesisService } from '@/services/speechSynthesisService';

interface UseVoiceRecognitionProps {
  onTranscript: (text: string, field: string) => void;
  conversationMode: boolean;
  chatGPT: EnhancedChatGPTService | null;
}

// Extension des types pour SpeechRecognition
interface ExtendedSpeechRecognition extends SpeechRecognition {
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

export const useVoiceRecognition = ({ onTranscript, conversationMode, chatGPT }: UseVoiceRecognitionProps) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [lastResponse, setLastResponse] = useState("");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConversationActive, setIsConversationActive] = useState(false);
  
  const recognitionRef = useRef<ExtendedSpeechRecognition | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const speechSynthesis = useRef(new SpeechSynthesisService()).current;
  const isStoppedRef = useRef(false);
  const autoRestartTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  const cleanupMicrophone = () => {
    console.log('ðŸ§¹ Nettoyage complet du microphone...');
    setIsListening(false);
    
    // Nettoyer tous les timeouts
    if (autoRestartTimeoutRef.current) {
      clearTimeout(autoRestartTimeoutRef.current);
      autoRestartTimeoutRef.current = null;
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => {
        console.log('ðŸ›‘ ArrÃªt track:', track.kind);
        track.stop();
      });
      mediaStreamRef.current = null;
    }

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.log('Recognition dÃ©jÃ  arrÃªtÃ©e');
      }
    }
  };

  const stopSpeaking = () => {
    console.log('ðŸ›‘ ARRÃŠT TOTAL - stopSpeaking appelÃ©');
    
    isStoppedRef.current = true;
    setIsConversationActive(false);
    speechSynthesis.stop();
    setIsSpeaking(false);
    setIsProcessing(false);
    
    if (autoRestartTimeoutRef.current) {
      clearTimeout(autoRestartTimeoutRef.current);
      autoRestartTimeoutRef.current = null;
    }
    
    console.log('âœ… IA complÃ¨tement arrÃªtÃ©e');
  };

  // Fonction simplifiÃ©e de redÃ©marrage automatique
  const scheduleRestart = (delay: number = 1000) => {
    console.log(`â° Programmation redÃ©marrage dans ${delay}ms`);
    console.log('ðŸ“Š Ã‰tat avant programmation:', {
      isStoppedRef: isStoppedRef.current,
      isConversationActive,
      isListening,
      isSpeaking,
      isProcessing
    });
    
    // Nettoyer ancien timeout
    if (autoRestartTimeoutRef.current) {
      clearTimeout(autoRestartTimeoutRef.current);
    }
    
    autoRestartTimeoutRef.current = setTimeout(async () => {
      console.log('ðŸ”„ TENTATIVE DE REDÃ‰MARRAGE');
      console.log('ðŸ“Š Ã‰tat au moment du redÃ©marrage:', {
        isStoppedRef: isStoppedRef.current,
        isConversationActive,
        isListening,
        isSpeaking,
        isProcessing
      });
      
      if (isStoppedRef.current || !isConversationActive) {
        console.log('âŒ RedÃ©marrage annulÃ© - conversation arrÃªtÃ©e');
        return;
      }

      if (isListening || isSpeaking || isProcessing) {
        console.log('âŒ RedÃ©marrage annulÃ© - autre activitÃ© en cours');
        return;
      }

      try {
        console.log('ðŸš€ REDÃ‰MARRAGE EFFECTIF DE L\'Ã‰COUTE');
        
        if (recognitionRef.current) {
          recognitionRef.current.start();
          setIsListening(true);
          console.log('âœ… Ã‰coute redÃ©marrÃ©e avec succÃ¨s');
        }
      } catch (error) {
        console.error('âŒ Erreur redÃ©marrage:', error);
        // Retry aprÃ¨s dÃ©lai plus long
        if (isConversationActive && !isStoppedRef.current) {
          console.log('ðŸ”„ Retry redÃ©marrage dans 2 secondes');
          scheduleRestart(2000);
        }
      }
    }, delay);
  };

  const processAIResponse = async (finalTranscript: string) => {
    console.log('ðŸ¤– === DÃ‰BUT processAIResponse ===');
    console.log('ðŸ¤– Input:', finalTranscript);
    console.log('ðŸ¤– conversationMode:', conversationMode);
    console.log('ðŸ¤– chatGPT disponible:', !!chatGPT);
    console.log('ðŸ“Š Ã‰tat conversation:', {
      isConversationActive,
      isStoppedRef: isStoppedRef.current
    });
    
    if (!conversationMode || !chatGPT) {
      console.log('âŒ Mode conversation dÃ©sactivÃ© ou ChatGPT non disponible');
      onTranscript(finalTranscript, "message");
      return;
    }

    if (isStoppedRef.current) {
      console.log('âŒ Traitement annulÃ© - conversation arrÃªtÃ©e via isStoppedRef');
      return;
    }

    if (!isConversationActive) {
      console.log('âŒ Traitement annulÃ© - conversation non active');
      return;
    }

    console.log('ðŸ¤– DÃ©but traitement IA...');
    setIsProcessing(true);
    
    // ArrÃªter l'Ã©coute pendant le traitement
    if (recognitionRef.current && isListening) {
      try {
        recognitionRef.current.stop();
        setIsListening(false);
        console.log('ðŸ›‘ Ã‰coute arrÃªtÃ©e pour traitement IA');
      } catch (error) {
        console.log('Recognition dÃ©jÃ  arrÃªtÃ©e');
      }
    }

    try {
      console.log('ðŸ“¤ Envoi Ã  ChatGPT...');
      const response = await chatGPT.sendMessage(finalTranscript);
      console.log('ðŸ“¥ RÃ©ponse ChatGPT reÃ§ue:', response.substring(0, 100) + '...');
      
      if (isStoppedRef.current || !isConversationActive) {
        console.log('âŒ Conversation arrÃªtÃ©e pendant traitement ChatGPT');
        setIsProcessing(false);
        return;
      }
      
      setLastResponse(response);
      setIsProcessing(false);
      setIsSpeaking(true);
      
      console.log('ðŸ”Š DÃ©but synthÃ¨se vocale...');
      
      // Parler avec callback pour redÃ©marrage
      speechSynthesis.speak(response, () => {
        console.log('âœ… SynthÃ¨se vocale terminÃ©e');
        setIsSpeaking(false);
        
        // VÃ©rifier encore les conditions avant redÃ©marrage
        console.log('ðŸŽ¯ VÃ©rification conditions pour redÃ©marrage aprÃ¨s synthÃ¨se');
        console.log('ðŸ“Š Ã‰tat aprÃ¨s synthÃ¨se:', {
          isStoppedRef: isStoppedRef.current,
          isConversationActive,
          isListening,
          isSpeaking: false
        });
        
        if (!isStoppedRef.current && isConversationActive) {
          console.log('ðŸŽ¯ Programmation redÃ©marrage aprÃ¨s synthÃ¨se');
          scheduleRestart(500);
        } else {
          console.log('âŒ RedÃ©marrage non programmÃ© aprÃ¨s synthÃ¨se');
        }
      });
      
    } catch (error) {
      console.error('âŒ Erreur ChatGPT:', error);
      setIsProcessing(false);
      setIsSpeaking(false);
      
      // RedÃ©marrer mÃªme en cas d'erreur
      if (!isStoppedRef.current && isConversationActive) {
        console.log('ðŸ”„ RedÃ©marrage aprÃ¨s erreur ChatGPT');
        scheduleRestart(2000);
      }
    }
    
    console.log('ðŸ¤– === FIN processAIResponse ===');
  };

  const startListening = async () => {
    console.log('ðŸŽ¯ startListening appelÃ©');
    console.log('ðŸ“Š Ã‰tat actuel:', {
      isListening,
      isConversationActive,
      recognitionAvailable: !!recognitionRef.current
    });
    
    if (!recognitionRef.current) {
      console.log('âŒ Recognition non disponible');
      return;
    }

    try {
      // Si conversation dÃ©jÃ  active, ne pas l'arrÃªter
      if (isConversationActive && isListening) {
        console.log('âœ… Conversation dÃ©jÃ  active, continue...');
        return;
      }

      // Si on Ã©tait en train de parler, arrÃªter
      if (isSpeaking) {
        console.log('ðŸ›‘ ArrÃªt de la synthÃ¨se en cours...');
        stopSpeaking();
        await new Promise(resolve => setTimeout(resolve, 100));
      }

      console.log('ðŸš€ DÃ©marrage nouvelle conversation');
      isStoppedRef.current = false;
      setIsConversationActive(true);

      // Obtenir le stream micro
      if (!mediaStreamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;
      }

      // DÃ©marrer la reconnaissance
      recognitionRef.current.start();
      setIsListening(true);
      
      console.log('ðŸŽ¤ Conversation continue dÃ©marrÃ©e avec succÃ¨s');
    } catch (error) {
      console.error('âŒ Erreur dÃ©marrage conversation:', error);
      cleanupMicrophone();
      setIsConversationActive(false);
    }
  };

  const stopListening = () => {
    console.log('ðŸ›‘ ArrÃªt complet de la conversation');
    setIsConversationActive(false);
    stopSpeaking();
    cleanupMicrophone();
  };

  // Configuration de la reconnaissance vocale
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognitionClass = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognitionClass() as ExtendedSpeechRecognition;
      recognitionRef.current = recognition;
      
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'fr-FR';

      recognition.onresult = (event) => {
        let finalTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript;
          }
        }
        
        if (finalTranscript.trim()) {
          console.log('ðŸŽ¯ Transcript final dÃ©tectÃ©:', finalTranscript);
          setTranscript(finalTranscript);
          
          // Traitement immÃ©diat du transcript
          console.log('âš¡ Traitement immÃ©diat du transcript');
          processAIResponse(finalTranscript);
        }
      };

      recognition.onerror = (event) => {
        console.error('âŒ Erreur reconnaissance:', event.error);
        setIsListening(false);
        
        // RedÃ©marrage automatique aprÃ¨s erreur
        if (isConversationActive && !isStoppedRef.current) {
          console.log('ðŸ”„ RedÃ©marrage aprÃ¨s erreur de reconnaissance');
          scheduleRestart(1500);
        }
      };

      recognition.onend = () => {
        console.log('ðŸ Reconnaissance terminÃ©e');
        setIsListening(false);
        
        console.log('ðŸ“Š Ã‰tat Ã  la fin de reconnaissance:', {
          isConversationActive,
          isStoppedRef: isStoppedRef.current,
          isSpeaking,
          isProcessing
        });
        
        // RedÃ©marrage automatique si conversation active
        if (isConversationActive && !isStoppedRef.current && !isSpeaking && !isProcessing) {
          console.log('ðŸ”„ Auto-redÃ©marrage aprÃ¨s fin normale');
          scheduleRestart(500);
        } else {
          console.log('âŒ Pas de redÃ©marrage - conditions non remplies');
        }
      };
    } else {
      console.error('âŒ Reconnaissance vocale non supportÃ©e');
    }

    return () => {
      cleanupMicrophone();
      stopSpeaking();
    };
  }, [onTranscript, conversationMode, chatGPT, isConversationActive, isSpeaking, isProcessing]);

  return {
    isListening,
    transcript,
    isProcessing,
    lastResponse,
    isSpeaking,
    isConversationActive,
    startListening,
    stopListening,
    stopSpeaking,
    cleanupMicrophone
  };
};
