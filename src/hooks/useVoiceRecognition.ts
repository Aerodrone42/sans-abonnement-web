
import { useState, useRef, useEffect } from 'react';
import { EnhancedChatGPTService } from '@/services/enhancedChatGptService';
import { SpeechSynthesisService } from '@/services/speechSynthesisService';

interface UseVoiceRecognitionProps {
  onTranscript: (text: string, field: string) => void;
  conversationMode: boolean;
  chatGPT: EnhancedChatGPTService | null;
}

interface ExtendedSpeechRecognition extends SpeechRecognition {
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

export const useVoiceRecognition = ({ onTranscript, conversationMode, chatGPT }: UseVoiceRecognitionProps) => {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [lastResponse, setLastResponse] = useState("");
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isConversationActive, setIsConversationActive] = useState(false);
  
  const recognitionRef = useRef<ExtendedSpeechRecognition | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const speechSynthesis = useRef(new SpeechSynthesisService()).current;
  const restartTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  
  const shouldContinueRef = useRef(false);
  const processingRef = useRef(false);
  const speakingRef = useRef(false);
  const lastTranscriptRef = useRef("");
  const interimResultRef = useRef("");
  const isStoppedRef = useRef(false);
  const microphoneMutedRef = useRef(false); // NOUVEAU: Flag pour couper le micro pendant la synth√®se

  const cleanup = () => {
    console.log('üßπ Nettoyage complet microphone');
    shouldContinueRef.current = false;
    speakingRef.current = false;
    isStoppedRef.current = true;
    microphoneMutedRef.current = false;
    setIsListening(false);
    
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }
    
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (error) {
        console.log('Recognition d√©j√† arr√™t√©e');
      }
    }
  };

  const stopSpeaking = () => {
    console.log('üõë ARR√äT COMPLET DEMAND√â');
    shouldContinueRef.current = false;
    speakingRef.current = false;
    isStoppedRef.current = true;
    microphoneMutedRef.current = false;
    setIsConversationActive(false);
    speechSynthesis.stop();
    setIsSpeaking(false);
    setIsProcessing(false);
    processingRef.current = false;
    cleanup();
  };

  // NOUVEAU: Couper le microphone pendant que l'IA parle
  const muteMicrophoneForSpeech = () => {
    console.log('üé§‚ùå MICRO COUP√â - IA va parler');
    microphoneMutedRef.current = true;
    
    if (recognitionRef.current && isListening) {
      try {
        recognitionRef.current.stop();
        setIsListening(false);
        console.log('üîá Reconnaissance vocale arr√™t√©e pendant synth√®se');
      } catch (error) {
        console.log('Erreur arr√™t recognition pour synth√®se');
      }
    }
  };

  // NOUVEAU: R√©activer le microphone apr√®s que l'IA a parl√©
  const unmuteMicrophoneAfterSpeech = () => {
    console.log('üé§‚úÖ MICRO R√âACTIV√â - IA a fini de parler');
    microphoneMutedRef.current = false;
    
    // Attendre un peu avant de red√©marrer pour √©viter que l'IA s'entende
    setTimeout(() => {
      if (isConversationActive && !isStoppedRef.current && !speakingRef.current && !processingRef.current) {
        console.log('üîÑ Red√©marrage micro apr√®s synth√®se');
        try {
          if (recognitionRef.current) {
            shouldContinueRef.current = true;
            recognitionRef.current.start();
            setIsListening(true);
            console.log('‚úÖ Micro red√©marr√© avec succ√®s');
          }
        } catch (error) {
          console.error('‚ùå Erreur red√©marrage micro:', error);
        }
      }
    }, 1000); // D√©lai de s√©curit√© de 1 seconde
  };

  const processAIResponse = async (finalTranscript: string) => {
    console.log('ü§ñ D√©but traitement IA:', finalTranscript);
    
    if (isStoppedRef.current || microphoneMutedRef.current) {
      console.log('‚ùå Traitement annul√© - conversation arr√™t√©e ou micro coup√©');
      return;
    }
    
    if (!finalTranscript || finalTranscript.trim().length < 2) {
      console.log('‚ùå Transcript trop court, ignor√©:', finalTranscript);
      return;
    }
    
    setIsProcessing(true);
    processingRef.current = true;
    
    // COUPER LE MICRO pendant le traitement
    muteMicrophoneForSpeech();
    
    if (!conversationMode || !chatGPT) {
      console.log('‚ùå Conditions non remplies - conversationMode:', conversationMode, 'chatGPT:', !!chatGPT);
      setTimeout(() => {
        setIsProcessing(false);
        processingRef.current = false;
        unmuteMicrophoneAfterSpeech();
        onTranscript(finalTranscript, "message");
      }, 1500);
      return;
    }

    try {
      console.log('üì§ Envoi √† ChatGPT...');
      const response = await chatGPT.sendMessage(finalTranscript);
      
      console.log('‚úÖ R√©ponse ChatGPT re√ßue:', response);
      
      setLastResponse(response);
      setIsSpeaking(true);
      speakingRef.current = true;
      
      console.log('üîä D√©but synth√®se vocale - micro restera coup√©');
      speechSynthesis.speak(response, () => {
        console.log('‚úÖ Synth√®se termin√©e - r√©activation du micro');
        setIsSpeaking(false);
        speakingRef.current = false;
        
        // R√âACTIVER LE MICRO apr√®s la synth√®se
        unmuteMicrophoneAfterSpeech();
      });
      
    } catch (error) {
      console.error('‚ùå Erreur ChatGPT:', error);
      
      // M√™me en cas d'erreur, r√©activer le micro
      setTimeout(() => {
        unmuteMicrophoneAfterSpeech();
      }, 2000);
    } finally {
      setTimeout(() => {
        setIsProcessing(false);
        processingRef.current = false;
        console.log('üèÅ Fin traitement IA');
      }, 2000);
    }
  };

  const startListening = async () => {
    console.log('üéØ D√âMARRAGE conversation');
    
    if (!recognitionRef.current) {
      console.log('‚ùå Recognition indisponible');
      return;
    }

    if (isSpeaking) {
      speechSynthesis.stop();
      setIsSpeaking(false);
      speakingRef.current = false;
    }

    try {
      if (!mediaStreamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;
        console.log('üé§ Permission micro obtenue');
      }

      shouldContinueRef.current = true;
      isStoppedRef.current = false;
      microphoneMutedRef.current = false;
      setIsConversationActive(true);

      recognitionRef.current.start();
      setIsListening(true);
      
      console.log('‚úÖ Conversation ACTIVE');
    } catch (error) {
      console.error('‚ùå Erreur d√©marrage:', error);
      cleanup();
    }
  };

  const stopListening = () => {
    console.log('üõë ARR√äT conversation demand√©');
    setIsConversationActive(false);
    stopSpeaking();
  };

  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognitionClass = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognitionClass() as ExtendedSpeechRecognition;
      recognitionRef.current = recognition;
      
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'fr-FR';

      recognition.onresult = (event) => {
        // V√âRIFICATION CRITIQUE: Ne pas traiter si arr√™t√© ou micro coup√©
        if (isStoppedRef.current || microphoneMutedRef.current) {
          console.log('‚ùå onresult ignor√© - conversation arr√™t√©e ou micro coup√©');
          return;
        }

        // V√âRIFICATION SUPPL√âMENTAIRE: Ignorer si l'IA parle
        if (speakingRef.current || processingRef.current) {
          console.log('‚ùå onresult ignor√© - IA parle ou traite');
          return;
        }

        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }
        
        if (interimTranscript) {
          interimResultRef.current = interimTranscript;
          setTranscript(lastTranscriptRef.current + interimTranscript);
        }
        
        if (finalTranscript.trim()) {
          console.log('üéØ TRANSCRIPT FINAL UTILISATEUR:', finalTranscript);
          lastTranscriptRef.current += finalTranscript;
          setTranscript(lastTranscriptRef.current);
          
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current);
          }
          
          // D√©lai de silence r√©duit pour une r√©activit√© am√©lior√©e
          silenceTimeoutRef.current = setTimeout(() => {
            if (lastTranscriptRef.current.trim() && !isStoppedRef.current && !microphoneMutedRef.current) {
              console.log('‚è∞ Traitement apr√®s silence de 3s:', lastTranscriptRef.current);
              processAIResponse(lastTranscriptRef.current.trim());
              lastTranscriptRef.current = "";
              interimResultRef.current = "";
              setTranscript("");
            }
          }, 3000); // R√©duit √† 3 secondes
        }
      };

      recognition.onerror = (event) => {
        console.error('‚ùå Erreur recognition:', event.error);
        setIsListening(false);
        
        // Ne red√©marrer que si pas d'erreur critique et micro non coup√©
        if (isConversationActive && !processingRef.current && !speakingRef.current && !isStoppedRef.current && !microphoneMutedRef.current) {
          console.log('üîÑ Red√©marrage apr√®s erreur dans 3s');
          restartTimeoutRef.current = setTimeout(() => {
            if (isConversationActive && !speakingRef.current && !processingRef.current && !isStoppedRef.current && !microphoneMutedRef.current && recognitionRef.current) {
              try {
                shouldContinueRef.current = true;
                recognitionRef.current.start();
                setIsListening(true);
              } catch (error) {
                console.error('Erreur red√©marrage:', error);
              }
            }
          }, 3000);
        }
      };

      recognition.onend = () => {
        console.log('üèÅ Recognition termin√©e');
        setIsListening(false);
        
        // Ne red√©marrer automatiquement que si conditions OK et micro pas coup√©
        if (isConversationActive && !processingRef.current && !speakingRef.current && !isStoppedRef.current && !microphoneMutedRef.current) {
          console.log('üîÑ Auto-restart recognition dans 1.5s');
          restartTimeoutRef.current = setTimeout(() => {
            if (isConversationActive && !speakingRef.current && !processingRef.current && !isStoppedRef.current && !microphoneMutedRef.current && recognitionRef.current) {
              try {
                shouldContinueRef.current = true;
                recognitionRef.current.start();
                setIsListening(true);
                console.log('‚úÖ Auto-restart r√©ussi');
              } catch (error) {
                console.error('Erreur auto-restart:', error);
              }
            }
          }, 1500);
        } else {
          console.log('üö´ Auto-restart ignor√© - conditions non remplies');
        }
      };
      
      console.log('üéôÔ∏è Speech Recognition configur√©e avec protection contre auto-√©coute');
    }

    return cleanup;
  }, [isConversationActive]);

  return {
    isListening,
    transcript,
    isProcessing,
    lastResponse,
    isSpeaking,
    isConversationActive,
    startListening,
    stopListening,
    stopSpeaking,
    cleanupMicrophone: cleanup
  };
};
